version: "3.8"
services: 
    hadoop1:
        image: yangqinjiang/hadoop-alone:latest
        container_name: hadoop1
        hostname: hadoop1
        tty: true
        ports: # 暴露端口信息  - "宿主机端口:容器暴露端口"
            - "1570:50070" # 更换端口, windows 10有权限限制, 所以用1570
            - "9000:9000"
        networks: 
            fixed:
                ipv4_address: "172.21.0.2"
        # redis 服务被限制为使用不超过 50M 的内存和 0.50（50％）的可用处理 时间（CPU），
        # 并且预留 20M 的内存和 0.25 个 CPU 时间。
        deploy:
            resources:
                limits:
                    cpus: '0.5' 
                    memory: 1024M
                reservations:
                    cpus: '0.25'
                    memory: 100M

    # zooKeeper 集群
    zookeeper:
        image: 'bitnami/zookeeper:latest'
        container_name: zookeeper
        hostname: zookeeper
        ports:
          - '2181:2181'
        extra_hosts: 
          - "hbase:172.21.0.6"
        deploy:
            resources:
                limits:
                    cpus: '0.5' 
                    memory: 128M
                reservations:
                    cpus: '0.25'
                    memory: 24M
        networks: 
            fixed:
                ipv4_address: "172.21.0.3"
        environment:
          - ALLOW_ANONYMOUS_LOGIN=yes
        user: root #注意看这里,添加了这一行后就可以解决
        volumes:
            - ./docker-data/zookeeper-persistence:/bitnami/zookeeper          
    # kafka
    kafka:
        image: 'bitnami/kafka:latest'
        container_name: kafka
        hostname: kafka
        ports:
            - '9092:9092'
        deploy:
            resources:
                limits:
                    cpus: '0.5' 
                    memory: 512M
                reservations:
                    cpus: '0.25'
                    memory: 48M
        networks: 
            fixed:
                ipv4_address: "172.21.0.4"
        environment:
            - KAFKA_BROKER_ID=1
            - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092
            - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://127.0.0.1:9092
            - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
            - ALLOW_PLAINTEXT_LISTENER=yes
        user: root #注意看这里,添加了这一行后就可以解决
        volumes:
            - ./docker-data/kafka-persistence/:/bitnami/kafka            
        depends_on:
            - zookeeper

    #  elasticsearch:6.8.17        
    elasticsearch:
        image: 'elasticsearch:6.8.17'
        container_name: elasticsearch
        hostname: elasticsearch
        ports:
            - '9200:9200'
        deploy:
            resources:
                limits:
                    cpus: '0.5' 
                    memory: 1024M
                reservations:
                    cpus: '0.25'
                    memory: 100M
        networks: 
            fixed:
                ipv4_address: "172.21.0.5"
        environment:
            - node.name=es01
            - discovery.type=single-node
            - bootstrap.memory_lock=true
            - "ES_JAVA_OPTS=-Xms900m -Xmx900m"
        #https://blog.csdn.net/weixin_30675247/article/details/96877923
        user: root #注意看这里,添加了这一行后就可以解决
        volumes:
            - ./elasticsearch:/usr/share/elasticsearch/data
        depends_on:
            - hadoop1

    #hbase
    hbase:
        image: yangqinjiang/hbase-standalone:latest
        container_name: hbase
        hostname: hbase
        links:
            - zookeeper
            - hadoop1
        depends_on: 
            - zookeeper
            - hadoop1
        extra_hosts: 
            - "zookeeper:172.21.0.3"
            - "hadoop1:172.21.0.2"
        ports:
            - "16010:16010"
        deploy:
            resources:
                limits:
                    cpus: '0.5' 
                    memory: 1024M
                reservations:
                    cpus: '0.25'
                    memory: 100M
        networks: 
            fixed:
                ipv4_address: "172.21.0.6"
        user: root #注意看这里,添加了这一行后就可以解决
        volumes:
            - ./docker-data/hbase:/data2
        expose:
            - "16000"
            - "16010"
            - "60010"
            - "16030"


    #redis
    redis:
        image: docker.io/bitnami/redis:6.2
        environment:
          # ALLOW_EMPTY_PASSWORD is recommended only for development.
          - ALLOW_EMPTY_PASSWORD=yes
        ports:
          - '6379:6379'
        depends_on: 
            - hadoop1          
        deploy:
            resources:
                limits:
                    cpus: '0.5' 
                    memory: 128M
                reservations:
                    cpus: '0.25'
                    memory: 20M          
        networks: 
            fixed:
                ipv4_address: "172.21.0.7"
        user: root #注意看这里,添加了这一行后就可以解决
        volumes:
          - './docker-data/redis_data:/bitnami/redis/data'

networks:
    fixed:
        ipam:
            driver: default
            config: 
                - subnet: "172.21.0.0/24"